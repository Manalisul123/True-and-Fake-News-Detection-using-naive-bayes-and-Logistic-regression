# True-and-Fake-News-Detection-using-naive-bayes-and-Logistic-regression
Using Naive Bayes & Logistic Regression (Python + scikit-learn)

## Overview
A machine learning pipeline to classify news articles as real (true) or fake using two classic models:

Multinomial Naive Bayes

Logistic Regression

The goal is to provide a clear, modular codebase for experimentation and evaluation of both algorithms with standard preprocessing: tokenization, TFâ€‘IDF, and model tuning.

## Features
Data preprocessing: text cleaning, stopword removal, tokenization, stemming/lemmatization

Feature extraction: CountVectorizer (Bagâ€‘ofâ€‘Words) and TfidfVectorizer

Two classifiers:

Naive Bayes (MultinomialNB with Laplace smoothing)

Logistic Regression (scikitâ€‘learn, L2 regularization, customizable C)

Model comparison by metrics: Accuracy, Precision, Recall, F1-score, Confusion matrix



ğŸ“ Project Structure

â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ train.csv
â”‚   â”œâ”€â”€ test.csv
â”‚   â””â”€â”€ (optional) validation.csv
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ preprocess.py
â”‚   â”œâ”€â”€ train.py
â”‚   â”œâ”€â”€ evaluate.py
â”‚   â””â”€â”€ predict.py
â”œâ”€â”€ models/
â”‚   â”œâ”€â”€ nb_model.pkl
â”‚   â””â”€â”€ lr_model.pkl
â”œâ”€â”€ requirements.txt
â””â”€â”€ README.md
# Requirements
Tested on:

Python 3.10+

scikit-learn

pandas, numpy

nltk (stopwords, stemmer or lemmatizer)


# Data Preparation
Place your labelled dataset in data/ (columns: text, label) with labels e.g. 1 = real, 0 = fake.



## Training Models
Train both models 



## Evaluation
Evaluate models on test data:


Model           Accuracy    Precision   Recall   F1-score
Naive Bayes       0.93         0.92       0.91      0.92
Logistic Reg.     0.95         0.95       0.94      0.95

## Prediction on New Samples

